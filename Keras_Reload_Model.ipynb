{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    BASE_DIR = ''\n",
    "    MAX_SEQUENCE_LENGTH = 1000\n",
    "    MAX_NUM_WORDS = 20000\n",
    "    TEXT_DATA_DIR = os.path.join(BASE_DIR, 'news_data')\n",
    "\n",
    "    #Reconstruct labels_index\n",
    "    labels = []\n",
    "    for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "        labels.append(name)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "    tokenizer.fit_on_texts([text])\n",
    "    sequences = tokenizer.texts_to_sequences([text])\n",
    "    x = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    y = np.argmax(model.predict(x, 1))\n",
    "    \n",
    "    print(\"Headline: {}\".format(text))\n",
    "    print(\"Prediction: {}\".format(labels[y]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline: Starbucks CEO Howard Schultz To Step Down\n",
      "Prediction: business\n",
      "\n",
      "Headline: Hefty Prison Sentence For Man Who Stole $1.2 Million In Fajitas\n",
      "Prediction: business\n",
      "\n",
      "Headline: James Corden Reveals The Worst Part Of The Royal Wedding Ceremony\n",
      "Prediction: business\n",
      "\n",
      "Headline: The Koch Network Is Going After One Of Trump’s Favorite Congressmen\n",
      "Prediction: entertainment\n",
      "\n",
      "['business', 'crime', 'entertainment', 'politics']\n"
     ]
    }
   ],
   "source": [
    "#business\n",
    "predict(\"Starbucks CEO Howard Schultz To Step Down\")\n",
    "#crime\n",
    "predict(\"Hefty Prison Sentence For Man Who Stole $1.2 Million In Fajitas\")\n",
    "\n",
    "predict(\"James Corden Reveals The Worst Part Of The Royal Wedding Ceremony\")\n",
    "\n",
    "predict(\"The Koch Network Is Going After One Of Trump’s Favorite Congressmen\")\n",
    "\n",
    "print(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
